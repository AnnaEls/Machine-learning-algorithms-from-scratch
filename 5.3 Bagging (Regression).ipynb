{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db8197ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4060e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLineReg():\n",
    "    \n",
    "    \n",
    "    def __init__(self, n_iter=100, learning_rate=0.1, w=None, metric = None, reg = None, l1_coef=0,l2_coef=0, sgd_sample = None, random_state=42): #class initialization\n",
    "        self.n_iter= n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.w = w\n",
    "        self.metric = metric\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.sgd_sample = sgd_sample\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}, w={self.w}, metric = {self.metric}, reg = {self.reg}, l1_coef={self.l1_coef}, l2_coef={self.l2_coef}, sgd_sample = {self.sgd_sample}, random_state={self.random_state}'\n",
    "    \n",
    "    #@classmethod\n",
    "    def fit(self, X, y, verbose):\n",
    "        X['new'] = 1\n",
    "        col = X.pop(\"new\")\n",
    "        X.insert(0, col.name, col)\n",
    "        random.seed(self.random_state)\n",
    "        N_of_features = len(X.columns)\n",
    "        self.w = np.ones(N_of_features)\n",
    "        for i in range(int(self.n_iter)):\n",
    "            y_ = np.dot(X,self.w)\n",
    "            X_data,y_data = self.select_data(X,y)\n",
    "            y_pred = np.dot(X_data,self.w)\n",
    "            MSE = np.square(np.subtract(y,y_)).mean() + self.reg_()[0]\n",
    "            grad_MSE = (2/len(y_data.values))*np.dot(np.subtract(y_pred,y_data),X_data) + self.reg_()[1]\n",
    "            if isinstance(self.learning_rate, float)== True:\n",
    "                self.w = self.w - self.learning_rate*grad_MSE\n",
    "            else:\n",
    "                self.w = self.w - self.learning_rate(i+1)*grad_MSE\n",
    "            if (verbose != False): \n",
    "                if (i%verbose ==0):\n",
    "                    print(f'{i}| loss:{MSE}')\n",
    "        \n",
    "                \n",
    "    def get_coef(self):\n",
    "        #self.fit(X,y,False)\n",
    "        return self.w[1:]\n",
    "    \n",
    "    def predict(self,X):\n",
    "        X['new'] = 1\n",
    "        col = X.pop(\"new\")\n",
    "        X.insert(0, col.name, col)\n",
    "        return np.dot(X, self.w)\n",
    "    \n",
    "    def calculate_metric(self, y, y_):\n",
    "        if self.metric == 'mse':\n",
    "            return np.square(np.subtract(y,y_)).mean() \n",
    "        elif self.metric == 'mae':\n",
    "            return np.abs(np.subtract(y,y_)).mean()\n",
    "        elif self.metric == 'rmse':\n",
    "            return np.sqrt(np.square(np.subtract(y,y_)).mean())\n",
    "        elif self.metric == 'mape':\n",
    "            return 100*(np.abs(np.subtract(y,y_)/y)).mean()\n",
    "        elif self.metric == 'r2':\n",
    "            return 1 - np.sum(np.square(np.subtract(y,y_)))/np.sum(np.square(np.subtract(y,y.mean())))\n",
    "        \n",
    "    def  get_best_score(self):\n",
    "        self.fit(X,y,False)\n",
    "        y_ = np.dot(X,self.w)\n",
    "        return self.calculate_metric(y, y_)\n",
    "\n",
    "    def  reg_(self):\n",
    "        reg_loss = 0\n",
    "        reg_grad = 0\n",
    "        if self.reg == 'l1':\n",
    "            reg_loss = self.l1_coef*np.sum(np.abs(self.w))\n",
    "            reg_grad = self.l1_coef*np.sign(self.w)\n",
    "        elif self.reg == 'l2':\n",
    "            reg_loss = self.l2_coef*np.sum(np.square(self.w))\n",
    "            reg_grad = 2*self.l2_coef*self.w\n",
    "        elif self.reg == 'elasticnet':\n",
    "            reg_loss = self.l1_coef*np.sum(np.abs(self.w))+self.l2_coef*np.sum(np.square(self.w))\n",
    "            reg_grad = self.l1_coef*np.sign(self.w)+2*self.l2_coef*self.w  \n",
    "        return reg_loss, reg_grad\n",
    "    \n",
    "    def select_data(self,X,y):\n",
    "        if self.sgd_sample == None:\n",
    "            return X, y\n",
    "        elif isinstance(self.sgd_sample,int) == True:\n",
    "            sample_rows_idx = random.sample(range(X.shape[0]), self.sgd_sample)\n",
    "            return X.iloc[sample_rows_idx,:], y.iloc[sample_rows_idx]\n",
    "        else:\n",
    "            sample_rows_idx = random.sample(range(X.shape[0]), int(self.sgd_sample*X.shape[0]))\n",
    "            return X.iloc[sample_rows_idx,:], y.iloc[sample_rows_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78139f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \n",
    "    def __init__(self, node_type = 'Node', side=None, feature = None, split_value = None, parent=None, *, node_depth = None,  ID = None, value = None, children=[]): #class initialization\n",
    "        self.node_type = node_type #Leaf or Node        \n",
    "        self.side = side #LEft or Right\n",
    "        self.feature = feature\n",
    "        self.split_value = split_value\n",
    "        self.parent = parent\n",
    "        \n",
    "        self.node_depth = node_depth \n",
    "        self.ID = ID\n",
    "        self.value = value #only for Leaf  \n",
    "        self.children = []\n",
    "        \n",
    "        self.Np = 0 #number of points in the node\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "    def add_child(self, new_value):\n",
    "        self.children.append(new_value)\n",
    "        \n",
    "class MyTreeReg():\n",
    "    \n",
    "    def __init__(self, max_depth = 5,  min_samples_split =2, max_leafs = 20, bins = None): \n",
    "        self.max_depth = max_depth #maximum possible depth of tree\n",
    "        self.min_samples_split = min_samples_split #minimum sample split\n",
    "        self.max_leafs = max_leafs #maximum possible number of leaves in a tree\n",
    "        self.bins = bins\n",
    "        \n",
    "        #tree parameters\n",
    "        self.tree = []\n",
    "        self.leafs_cnt = 0 #number of created leaves in the tree\n",
    "        self.potential_leafs_cnt = 1 #counting potential leaves\n",
    "        self.leafs_sum = 0 #sum of the leaves values\n",
    "        \n",
    "        self.histogram = {}\n",
    "        \n",
    "        self.fi = {}\n",
    "        \n",
    "        self.N = 0\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'MyTreeReg class: max_depth={self.max_depth}, min_samples_split={self.min_samples_split}, max_leafs={self.max_leafs}'\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------\n",
    "    def fit(self, X, y): #receives panda dataframe and series\n",
    "        if self.bins != None:\n",
    "            for feature in X.columns:\n",
    "                self.histogram.update({feature: self.get_hist_delimeters(X[feature].values)})\n",
    "                \n",
    "        for feature in X.columns:\n",
    "            self.fi.update({feature: 0})\n",
    "        \n",
    "        self.N = len(y.values)\n",
    "        \n",
    "        #Create root node\n",
    "        feature, split_value, ig = self.get_best_split(X,y)\n",
    "        X_left, y_left, X_right, y_right = self.split_dataframe(X, y, feature, split_value)\n",
    "        if ig == 0.0 or len(y_left) == 0 or len(y_right) == 0:            \n",
    "            print('All targets belong to class:', np.sum(y.values)/len(y.values) )\n",
    "        else:\n",
    "            _node = self.register_Node(\"Node\", None, feature, split_value, None, y)\n",
    "            #--------feature importance update---\n",
    "            _node.Np = len(y.values)\n",
    "            self.update_fi(y, _node, None)\n",
    "            #----------------------------------\n",
    "            self.grow_tree(X_left, y_left, 'Left', _node)\n",
    "            self.grow_tree(X_right, y_right, 'Right', _node)\n",
    "            \n",
    "        \n",
    "    def grow_tree(self, X, y, side, parent): #receives panda dataframe and series, string and Node\n",
    "        feature, split_value, ig = self.get_best_split(X,y)\n",
    "        X_left, y_left, X_right, y_right = self.split_dataframe(X, y, feature, split_value)\n",
    "        \n",
    "        if ig != 0.0 and len(y_left) != 0 and len(y_right) != 0 and (parent.node_depth < self.max_depth) and (len(y.values) >= self.min_samples_split) and (self.leafs_cnt + self.potential_leafs_cnt < self.max_leafs):\n",
    "            _node = self.register_Node('Node', side, feature, split_value, parent, y)\n",
    "            #--------feature importance update---\n",
    "            _node.Np = len(y.values)\n",
    "            self.update_fi(y, _node, parent)\n",
    "            #----------------------------------\n",
    "            self.grow_tree(X_left, y_left, 'Left', _node)\n",
    "            self.grow_tree(X_right, y_right, 'Right', _node)\n",
    "        else:\n",
    "            _node = self.register_Node('Leaf', side, feature, split_value, parent, y)\n",
    "            #--------feature importance update---\n",
    "            _node.Np = len(y.values)\n",
    "            self.update_fi(y, _node, parent)\n",
    "            #----------------------------------\n",
    "            return _node\n",
    "            \n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    def register_Node(self, node_type, side, feature, split_value, parent, y):\n",
    "        #1.setting node depth\n",
    "        if parent != None:\n",
    "            node_depth = parent.node_depth +1\n",
    "        else:\n",
    "            node_depth = 1\n",
    "            \n",
    "        #2.setting node ID\n",
    "        if node_type == 'Node':\n",
    "            if side == 'Left':\n",
    "                 ID = parent.ID + '.1' \n",
    "            elif side == 'Right':\n",
    "                 ID = parent.ID + '.2'\n",
    "            else:\n",
    "                ID = '1'\n",
    "        \n",
    "        if node_type == 'Leaf':\n",
    "            ID = parent.ID\n",
    "            \n",
    "        #3.Setting node value\n",
    "        if node_type == 'Leaf':\n",
    "            value = np.mean(y.values)\n",
    "        else:\n",
    "            value = None\n",
    "        \n",
    "        new_node = Node(node_type, side, feature, split_value, parent, node_depth=node_depth, ID=ID, value=value)\n",
    "        self.tree.append(new_node)\n",
    "        \n",
    "        #add as a child to parent node\n",
    "        if parent != None :                            \n",
    "            parent.add_child(new_node)\n",
    "            \n",
    "        #update counts\n",
    "        if node_type == \"Node\":\n",
    "            self.potential_leafs_cnt = self.potential_leafs_cnt + 1\n",
    "        elif node_type == \"Leaf\":\n",
    "            self.leafs_cnt = self.leafs_cnt + 1\n",
    "            self.potential_leafs_cnt = self.potential_leafs_cnt - 1\n",
    "            self.leafs_sum = self.leafs_sum + value\n",
    "        return new_node\n",
    "        \n",
    "            \n",
    "    def print_tree_full(self):\n",
    "        for node in self.tree:\n",
    "                print(node.__dict__)\n",
    "    \n",
    "    def print_tree(self):\n",
    "        for node in self.tree:\n",
    "            if node.node_type == 'Node':\n",
    "                \n",
    "                print(node.__dict__['ID'], node.__dict__['feature'], '>', node.__dict__['split_value'])\n",
    "            else:\n",
    "                print(node.__dict__['ID'],node.__dict__['side'], '-', node.__dict__['value'])\n",
    "                \n",
    "    def move_up_the_tree(self, X, _node,i):\n",
    "        if _node.node_type =='Leaf':\n",
    "            self.predictions[i]=float(_node.value)\n",
    "        elif _node.node_type =='Node': \n",
    "            if X[_node.feature] <= _node.split_value:\n",
    "                if _node.children[0].side =='Left':\n",
    "                    self.move_up_the_tree(X, _node.children[0],i)\n",
    "                else: self.move_up_the_tree(X, _node.children[1],i)\n",
    "               \n",
    "            else:\n",
    "                if _node.children[0].side =='Right':\n",
    "                    self.move_up_the_tree(X, _node.children[0],i)\n",
    "                else: self.move_up_the_tree(X, _node.children[1],i)\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    def predict(self,X):\n",
    "        self.predictions = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            self.move_up_the_tree(X.iloc[i,:], self.tree[0],i)\n",
    "        return(self.predictions)\n",
    "        \n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    #Calculate the best split\n",
    "    def MSE(self, y): # receives 1D numpy array\n",
    "        return np.mean(np.square(y-np.mean(y)))\n",
    "\n",
    "    def data_split(self, X, y, threshold): #receives two 1D numpy arrays and a float\n",
    "        X_left = X[X <= threshold]\n",
    "        y_left = y[X <= threshold]\n",
    "        X_right = X[X > threshold]\n",
    "        y_right = y[X > threshold]\n",
    "        return X_left, y_left, X_right, y_right\n",
    "    \n",
    "    def get_IG(self, X, y, threshold): #receives two numpy arrays and a float\n",
    "        #split the data by the threshold\n",
    "        _, y_left, __, y_right = self.data_split(X, y, threshold)\n",
    "        if len(y_left) == 0 or len(y_right) == 0: #threshold does not split the data\n",
    "            return 0.0\n",
    "        else:\n",
    "            S0 = self.MSE(y)\n",
    "            S1 = self.MSE(y_left)*len(y_left)/len(y)\n",
    "            S2 = self.MSE(y_right)*len(y_right)/len(y)\n",
    "            IG = S0 - S1 -S2\n",
    "            return IG\n",
    "        \n",
    "    def get_native_delimeters(self, X): #receives 1D numpy array\n",
    "        X_unique = np.unique(np.sort(X))\n",
    "        native_delimeters = [np.mean([X_unique[i-1], X_unique[i]]) for i in range(1, len(X_unique))]\n",
    "        return native_delimeters\n",
    "    \n",
    "    def get_hist_delimeters(self, X): #receives 1D numpy array\n",
    "        hist_delimeters = np.histogram(X, self.bins)[1][1:-1]\n",
    "        return hist_delimeters\n",
    "    \n",
    "    def get_best_split(self, X, y): #receives panda dataframe and panda series\n",
    "        feature_best_split = {}\n",
    "        for feature in X.columns:\n",
    "            if len(X[feature].values) == 0 or np.max(X[feature].values) == np.min(X[feature].values):\n",
    "                feature_best_split.update({feature: [None, 0.0]}) #feature has no values or any delimeters\n",
    "            else:\n",
    "                if self.bins == None:                    \n",
    "                    feature_delimeters = self.get_native_delimeters(X[feature].values)\n",
    "                else: \n",
    "                    X_unique = np.unique(np.sort(X))\n",
    "                    if len(X_unique) <= self.bins:\n",
    "                        feature_delimeters = self.get_native_delimeters(X[feature].values)\n",
    "                    else:\n",
    "                         feature_delimeters = self.histogram[feature]\n",
    "                    \n",
    "                feature_igs = [self.get_IG(X[feature].values, y.values, feature_delimeters[i]) for i in range(len(feature_delimeters))]\n",
    "                feature_best_split.update({feature: [feature_delimeters[np.argmax(feature_igs)],np.max(feature_igs)]})\n",
    "        \n",
    "        split_value, ig   = max(feature_best_split.values(), key=lambda x: x[1])\n",
    "        feature = next(k for k, v in feature_best_split.items() if v == [split_value, ig])\n",
    "        return feature, split_value, ig\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "    def split_dataframe(self, X, y, feature, threshold): #X,y - np.arrays, threshold - float\n",
    "        X_left = X[X[feature] <= threshold].reset_index(drop = True)\n",
    "        y_left = y[X[feature] <= threshold].reset_index(drop = True)\n",
    "        X_right = X[X[feature] > threshold].reset_index(drop = True)\n",
    "        y_right = y[X[feature] > threshold].reset_index(drop = True)\n",
    "        return X_left, y_left, X_right, y_right\n",
    "    \n",
    "    def update_fi(self, y, _node, parent):\n",
    "        if _node.node_type == 'Node':\n",
    "            FI = self.MSE(y.values)*_node.Np/self.N         \n",
    "            self.fi.update({_node.feature: self.fi[_node.feature] + FI })\n",
    "        \n",
    "        if parent != None:\n",
    "            FI = self.MSE(y.values)*_node.Np/self.N\n",
    "            self.fi.update({parent.feature: self.fi[parent.feature] - FI })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c47cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKNNReg():\n",
    "    \n",
    "    def __init__(self, k=3, metric = 'euclidean', weight = 'uniform'): #class initialization\n",
    "        self.k = k\n",
    "        self.train_size = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.metric = metric\n",
    "        self.weight = weight\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'MyKNNClf class: k={self.k}'\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X.copy()\n",
    "        self.y_train = y.copy()\n",
    "        self.train_size = X.shape\n",
    "        \n",
    "    def euclidian(self, Xtest, Xtrain):\n",
    "        return np.sqrt(np.sum((Xtest[:,np.newaxis]-Xtrain)**2, axis=2))\n",
    "    \n",
    "    def chebyshev(self, Xtest, Xtrain):\n",
    "        return np.max(np.abs(Xtest[:,np.newaxis]-Xtrain), axis=2)\n",
    "    \n",
    "    def manhattan(self, Xtest, Xtrain):\n",
    "        return np.sum(np.abs(Xtest[:,np.newaxis]-Xtrain), axis=2)\n",
    "    \n",
    "    def cosine(self, Xtest, Xtrain):\n",
    "        Xtest_norm = np.linalg.norm(Xtest, axis=1)\n",
    "        Xtrain_norm = np.linalg.norm(Xtrain, axis=1)\n",
    "        return 1 - np.dot(Xtest, Xtrain.T)/(Xtest_norm[:,np.newaxis]*Xtrain_norm)\n",
    "    \n",
    "    def calculate_metric(self,X):\n",
    "        if self.metric == 'chebyshev':\n",
    "            return self.chebyshev(X.values, self.X_train.values)\n",
    "        if self.metric == 'manhattan':\n",
    "            return self.manhattan(X.values, self.X_train.values)\n",
    "        if self.metric == 'cosine':\n",
    "            return self.cosine(X.values, self.X_train.values)\n",
    "        if self.metric == 'euclidean':\n",
    "            return self.euclidian(X.values, self.X_train.values)\n",
    "        \n",
    "    def get_rank(self,X):\n",
    "        D = self.calculate_metric(X)\n",
    "        min_k = np.array(self.y_train.values[np.argsort(D,axis=1)][:,:self.k])\n",
    "        weight = (1/(np.arange(self.k)+1))/np.sum(1/(np.arange(self.k)+1)) \n",
    "        return min_k*weight\n",
    "    \n",
    "    def get_dist(self,X):\n",
    "        D = self.calculate_metric(X)\n",
    "        min_k = self.y_train.values[np.argsort(D,axis=1)][:,:self.k]\n",
    "        D_min_k = np.sort(D,axis=1)[:,:self.k]     \n",
    "        weight = 1/D_min_k/np.sum(1/D_min_k, axis=1)[:,np.newaxis]\n",
    "        return min_k*weight\n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict(self,X):\n",
    "        if self.weight == 'uniform':\n",
    "            D = self.calculate_metric(X)\n",
    "            min_k = np.array(self.y_train.values[np.argsort(D,axis=1)][:,:self.k])\n",
    "            return np.sum(min_k, axis =1)/self.k\n",
    "        \n",
    "        elif self.weight == 'rank':\n",
    "            return self.get_rank(X)\n",
    "        \n",
    "        elif self.weight == 'distance':\n",
    "            return self.get_dist(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7291079",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBaggingReg():\n",
    "    \n",
    "    def __init__(self, estimator=None, n_estimators=10, max_samples=1.0, random_state=42, oob_score = None): #cla ss initialization\n",
    "        self.estimator= estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_samples = max_samples\n",
    "        self.random_state = random_state\n",
    "        self.estimators = [None]*self.n_estimators\n",
    "        \n",
    "        self.oob_score = oob_score\n",
    "        self.oob_score_ = 0\n",
    "        self.OOB_predictions = {}\n",
    "        \n",
    "        \n",
    "     \n",
    "    def __repr__(self):\n",
    "        return f'MyBaggingReg class: estimator={self.estimator}, n_estimators={self.n_estimators}, max_samples={self.max_samples}, random_state={self.random_state}'\n",
    "    \n",
    "    \n",
    "    def  fit(self, X, y): #received pandas dataframe and series\n",
    "        if self.oob_score != None:\n",
    "            for i in range(X.shape[0]):\n",
    "                self.OOB_predictions.update({str(i): np.zeros(0)})\n",
    "        \n",
    "        \n",
    "        \n",
    "        #1 Create bootstrap sample from the original dataset\n",
    "        random.seed(self.random_state)\n",
    "        rows_smpl_cnt = int(np.round(self.max_samples*X.shape[0],0))\n",
    "        rows_list = np.zeros([rows_smpl_cnt, self.n_estimators])\n",
    "        for i in range(self.n_estimators):\n",
    "            rows_list[:,i] = random.choices(list(X.index), k=rows_smpl_cnt)\n",
    "            \n",
    "        for i in range(self.n_estimators):\n",
    "            self.estimators[i] = copy.deepcopy(self.estimator)\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            if self.estimator.__class__.__name__ == 'MyLineReg':\n",
    "                self.estimators[i].fit(X.loc[rows_list[:,i]],y.loc[rows_list[:,i]],False)\n",
    "            else:\n",
    "                self.estimators[i].fit(X.loc[rows_list[:,i]],y.loc[rows_list[:,i]])\n",
    "         \n",
    "            \n",
    "            if self.oob_score != None:\n",
    "                X_oob = X.drop(rows_list[:,i])\n",
    "                y_oob = y.drop(rows_list[:,i]).reset_index()\n",
    "                predictions = self.estimators[i].predict(X_oob)\n",
    "                for i in range(y_oob.shape[0]):\n",
    "                    temp = np.append(self.OOB_predictions[str(y_oob['index'][i])],predictions[i])\n",
    "                    self.OOB_predictions.update({str(y_oob['index'][i]): temp })\n",
    "                \n",
    "                \n",
    "                    \n",
    "        if self.oob_score != None:\n",
    "            y1 = np.zeros(0)\n",
    "            y2 = np.zeros(0)\n",
    "            for index, array in self.OOB_predictions.items():\n",
    "                if len(array) != 0:\n",
    "                    y1=np.append(y1, y.values[int(index)])\n",
    "                    y2=np.append(y2, np.mean(array))\n",
    "                \n",
    "            self.oob_score_ = self.calculate_metric(y1, y2)\n",
    "        \n",
    "                \n",
    "    def  predict(self, X):\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "        for i in range(len(self.estimators)):\n",
    "            predictions = predictions +  self.estimators[i].predict(X)\n",
    "            \n",
    "        return predictions/len(self.estimators)\n",
    "    \n",
    "    def calculate_metric(self, y, y_):\n",
    "        if self.oob_score == 'mse':\n",
    "            return np.square(np.subtract(y,y_)).mean() \n",
    "        elif self.oob_score == 'mae':\n",
    "            return np.abs(np.subtract(y,y_)).mean()\n",
    "        elif self.oob_score == 'rmse':\n",
    "            return np.sqrt(np.square(np.subtract(y,y_)).mean())\n",
    "        elif self.oob_score == 'mape':\n",
    "            return 100*(np.abs(np.subtract(y,y_)/y)).mean()\n",
    "        elif self.oob_score == 'r2':\n",
    "            return 1 - np.sum(np.square(np.subtract(y,y_)))/np.sum(np.square(np.subtract(y,y.mean()))) \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
