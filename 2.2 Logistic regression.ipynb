{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b618220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7696eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogReg():\n",
    "    \n",
    "      \n",
    "    def __init__(self, n_iter=10, learning_rate=0.1, w=None, metric=None,reg = None, l1_coef=0,l2_coef=0,sgd_sample = None, random_state=42): #cla ss initialization\n",
    "        self.n_iter= n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.w = w\n",
    "        self.metric = metric\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.sgd_sample = sgd_sample\n",
    "        self.random_state = random_state\n",
    "     \n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}'\n",
    "    \n",
    "    def fit(self, X, y, verbose=False):\n",
    "        eps = 1e-15\n",
    "        X['new'] = 1\n",
    "        col = X.pop(\"new\")\n",
    "        X.insert(0, col.name, col)\n",
    "        random.seed(self.random_state)\n",
    "        N_of_features = len(X.columns)\n",
    "        self.w = np.ones(N_of_features)\n",
    "        for i in range(int(self.n_iter)):               \n",
    "            y_ = 1/(1+np.exp(-np.dot(X,self.w)))\n",
    "            X_data,y_data = self.select_data(X,y)\n",
    "            y_pred = 1/(1+np.exp(-np.dot(X_data,self.w)))\n",
    "            LogLoss = -(y*np.log(y_+eps)+(1-y)*(1-np.log(1-y_+eps))).mean() + self.reg_()[0]\n",
    "            grad_Log = (1/len(y_data))*np.dot(np.subtract(y_pred,y_data),X_data) + self.reg_()[1]\n",
    "            if isinstance(self.learning_rate, float)== True:\n",
    "                self.w = self.w - self.learning_rate*grad_Log\n",
    "            else:\n",
    "                self.w = self.w - self.learning_rate(i+1)*grad_Log\n",
    "            if (verbose != False): \n",
    "                if (i%verbose ==0):\n",
    "                    print(f'{i}| loss:{LogLoss}')\n",
    "        \n",
    "                \n",
    "    def get_coef(self):\n",
    "        \n",
    "        return self.w[1:]\n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        X['new'] = 1\n",
    "        col = X.pop(\"new\")\n",
    "        X.insert(0, col.name, col)\n",
    "        return 1/(1+np.exp(-np.dot(X,self.w)))\n",
    "    \n",
    "    def predict(self,X):\n",
    "        X['new'] = 1\n",
    "        col = X.pop(\"new\")\n",
    "        X.insert(0, col.name, col)\n",
    "        P = 1/(1+np.exp(-np.dot(X,self.w)))\n",
    "        classes = np.zeros(P.shape,dtype=np.int)\n",
    "        classes[np.where(P > 0.5)]=1\n",
    "        return classes\n",
    "    \n",
    "    def get_best_score(self):\n",
    "        y_classes = self.predict(X)\n",
    "        TP=np.count_nonzero((y==1)&(y_classes==1))\n",
    "        TN = np.count_nonzero((y==0)&(y_classes==0))\n",
    "        FP = np.count_nonzero((y==0)&(y_classes==1))\n",
    "        FN = np.count_nonzero((y==1)&(y_classes==0))\n",
    "        return self.calculate_metric(TP, TN, FP, FN)\n",
    "    \n",
    "    def calculate_metric(self, TP, TN, FP, FN, beta = 1):\n",
    "        global y\n",
    "        if self.metric == 'accuracy':\n",
    "            return (TP+TN)/(TP+TN+FP+FN)\n",
    "        elif self.metric == 'precision':\n",
    "            return TP/(TP+FP)\n",
    "        elif self.metric == 'recall':\n",
    "            return TP/(TP+FN)\n",
    "        elif self.metric == 'f1':\n",
    "            pres = TP/(TP+FP)\n",
    "            rec = TP/(TP+FN)\n",
    "            return (1+np.square(beta))*pres*rec/(np.square(beta)*pres + rec)\n",
    "        elif self.metric == 'roc_auc':\n",
    "            probs = self.predict_proba(X)\n",
    "            sorted_idx = np.argsort(-probs)\n",
    "            probs_sorted = probs[sorted_idx]\n",
    "            y_sorted = y[sorted_idx]\n",
    "            \n",
    "            sum=0.\n",
    "            P = len(np.where(y==1)[0])\n",
    "            N = len(np.where(y==0)[0])\n",
    "            \n",
    "            \n",
    "            for prob, class_ in zip(probs_sorted,y_sorted):\n",
    "                if class_ == 0:\n",
    "                    sum = sum + len(np.where(y_sorted[probs_sorted > prob]==1)[0])\n",
    "                    sum = sum + 0.5*len(np.where(y_sorted[probs_sorted == prob]==1)[0])\n",
    "            return sum/(P*N)       \n",
    "        \n",
    "    def  reg_(self):\n",
    "        reg_loss = 0\n",
    "        reg_grad = 0\n",
    "        if self.reg == 'l1':\n",
    "            reg_loss = self.l1_coef*np.sum(np.abs(self.w))\n",
    "            reg_grad = self.l1_coef*np.sign(self.w)\n",
    "        elif self.reg == 'l2':\n",
    "            reg_loss = self.l2_coef*np.sum(np.square(self.w))\n",
    "            reg_grad = 2*self.l2_coef*self.w\n",
    "        elif self.reg == 'elasticnet':\n",
    "            reg_loss = self.l1_coef*np.sum(np.abs(self.w))+self.l2_coef*np.sum(np.square(self.w))\n",
    "            reg_grad = self.l1_coef*np.sign(self.w)+2*self.l2_coef*self.w  \n",
    "        return reg_loss, reg_grad\n",
    "    \n",
    "    def select_data(self,X,y):\n",
    "        if self.sgd_sample == None:\n",
    "            return X, y\n",
    "        elif isinstance(sgd_sample,int) == True:\n",
    "            sample_rows_idx = random.sample(range(X.shape[0]), self.sgd_sample)\n",
    "            return X.iloc[sample_rows_idx,:], y.iloc[sample_rows_idx]\n",
    "        else:\n",
    "            sample_rows_idx = random.sample(range(X.shape[0]), int(self.sgd_sample*X.shape[0]))\n",
    "            return X.iloc[sample_rows_idx,:], y.iloc[sample_rows_idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
