{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60504849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd18c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLineReg():\n",
    "    \n",
    "    \n",
    "    def __init__(self, n_iter=100, learning_rate=0.1, w=None, metric = None, reg = None, l1_coef=0,l2_coef=0, sgd_sample = None, random_state=42): #class initialization\n",
    "        self.n_iter= n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.w = w\n",
    "        self.metric = metric\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.sgd_sample = sgd_sample\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}, w={self.w}, metric = {self.metric}, reg = {self.reg}, l1_coef={self.l1_coef}, l2_coef={self.l2_coef}, sgd_sample = {self.sgd_sample}, random_state={self.random_state}'\n",
    "    \n",
    "    #@classmethod\n",
    "    def fit(self, X, y, verbose):\n",
    "        X['new'] = 1\n",
    "        col = X.pop(\"new\")\n",
    "        X.insert(0, col.name, col)\n",
    "        random.seed(self.random_state)\n",
    "        N_of_features = len(X.columns)\n",
    "        self.w = np.ones(N_of_features)\n",
    "        for i in range(int(self.n_iter)):\n",
    "            y_ = np.dot(X,self.w)\n",
    "            X_data,y_data = self.select_data(X,y)\n",
    "            y_pred = np.dot(X_data,self.w)\n",
    "            MSE = np.square(np.subtract(y,y_)).mean() + self.reg_()[0]\n",
    "            grad_MSE = (2/len(y_data.values))*np.dot(np.subtract(y_pred,y_data),X_data) + self.reg_()[1]\n",
    "            if isinstance(self.learning_rate, float)== True:\n",
    "                self.w = self.w - self.learning_rate*grad_MSE\n",
    "            else:\n",
    "                self.w = self.w - self.learning_rate(i+1)*grad_MSE\n",
    "            if (verbose != False): \n",
    "                if (i%verbose ==0):\n",
    "                    print(f'{i}| loss:{MSE}')\n",
    "        \n",
    "                \n",
    "    def get_coef(self):\n",
    "        return self.w[1:]\n",
    "    \n",
    "    def predict(self,X):\n",
    "        X['new'] = 1\n",
    "        col = X.pop(\"new\")\n",
    "        X.insert(0, col.name, col)\n",
    "        return np.dot(X, self.w)\n",
    "    \n",
    "    def calculate_metric(self, y, y_):\n",
    "        if self.metric == 'mse':\n",
    "            return np.square(np.subtract(y,y_)).mean() \n",
    "        elif self.metric == 'mae':\n",
    "            return np.abs(np.subtract(y,y_)).mean()\n",
    "        elif self.metric == 'rmse':\n",
    "            return np.sqrt(np.square(np.subtract(y,y_)).mean())\n",
    "        elif self.metric == 'mape':\n",
    "            return 100*(np.abs(np.subtract(y,y_)/y)).mean()\n",
    "        elif self.metric == 'r2':\n",
    "            return 1 - np.sum(np.square(np.subtract(y,y_)))/np.sum(np.square(np.subtract(y,y.mean())))\n",
    "        \n",
    "    def  get_best_score(self):\n",
    "        self.fit(X,y,False)\n",
    "        y_ = np.dot(X,self.w)\n",
    "        return self.calculate_metric(y, y_)\n",
    "\n",
    "    def  reg_(self):\n",
    "        reg_loss = 0\n",
    "        reg_grad = 0\n",
    "        if self.reg == 'l1':\n",
    "            reg_loss = self.l1_coef*np.sum(np.abs(self.w))\n",
    "            reg_grad = self.l1_coef*np.sign(self.w)\n",
    "        elif self.reg == 'l2':\n",
    "            reg_loss = self.l2_coef*np.sum(np.square(self.w))\n",
    "            reg_grad = 2*self.l2_coef*self.w\n",
    "        elif self.reg == 'elasticnet':\n",
    "            reg_loss = self.l1_coef*np.sum(np.abs(self.w))+self.l2_coef*np.sum(np.square(self.w))\n",
    "            reg_grad = self.l1_coef*np.sign(self.w)+2*self.l2_coef*self.w  \n",
    "        return reg_loss, reg_grad\n",
    "    \n",
    "    def select_data(self,X,y):\n",
    "        if self.sgd_sample == None:\n",
    "            return X, y\n",
    "        elif isinstance(self.sgd_sample,int) == True:\n",
    "            sample_rows_idx = random.sample(range(X.shape[0]), self.sgd_sample)\n",
    "            return X.iloc[sample_rows_idx,:], y.iloc[sample_rows_idx]\n",
    "        else:\n",
    "            sample_rows_idx = random.sample(range(X.shape[0]), int(self.sgd_sample*X.shape[0]))\n",
    "            return X.iloc[sample_rows_idx,:], y.iloc[sample_rows_idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
